RAG-Based Conversational AI with Memory using Streamlit & LangChain
ðŸ“Œ Overview
This project implements a Retrieval-Augmented Generation (RAG) Conversational AI system using LangChain, Streamlit, and Groq API (LLM). It enhances chatbot capabilities by retrieving relevant documents and maintaining contextual memory across interactions.

ðŸ”¹ Features
âœ… Conversational Memory â€“ Tracks user history using RunnableWithMessageHistory.
âœ… RAG-based Retrieval â€“ Uses VectorStoreRetriever to fetch relevant documents.
âœ… History-Aware Querying â€“ Enhances retrieval via create_history_aware_retriever().
âœ… Streamlit UI â€“ Interactive chatbot interface with session-based memory.
âœ… Groq API for LLM â€“ Utilizes Groqâ€™s API to generate responses.

ðŸ›  Tech Stack
Backend: Python, LangChain, Groq API
Frontend: Streamlit
Vector Store: FAISS / ChromaDB (for document retrieval)
Memory Management: BaseChatMessageHistory
